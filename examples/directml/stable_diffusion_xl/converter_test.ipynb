{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Axodox\\miniconda3\\envs\\olive-3x\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import shutil\n",
    "import warnings\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import onnxruntime as ort\n",
    "import torch\n",
    "from diffusers import OnnxRuntimeModel, OnnxStableDiffusionPipeline, StableDiffusionPipeline\n",
    "from packaging import version\n",
    "\n",
    "from olive.workflows import run as olive_run\n",
    "from google.protobuf import __version__ as protobuf_version\n",
    "\n",
    "ort.set_default_logger_severity(4)\n",
    "script_dir = Path(os.path.dirname(os.path.abspath('__file__')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE conversion\n",
    "\n",
    "olive_config = None\n",
    "#submodel_name = \"vae_decoder\"\n",
    "submodel_name = \"unet\"\n",
    "olice_config_path = script_dir / f\"config_{submodel_name}.json\"\n",
    "olive_config_file = open(olice_config_path, \"r\")\n",
    "olive_config = json.load(olive_config_file)\n",
    "olive_config[\"input_model\"][\"config\"][\"model_path\"] = \"stablediffusionapi/protovisionxl-v3\"\n",
    "olive_config[\"input_model\"][\"config\"][\"model_script\"] = \"user_script.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlnet conversion\n",
    "\n",
    "olive_config = None\n",
    "submodel_name = \"controlnet\"\n",
    "olice_config_path = script_dir / f\"config_{submodel_name}.json\"\n",
    "olive_config_file = open(olice_config_path, \"r\")\n",
    "olive_config = json.load(olive_config_file)\n",
    "olive_config[\"input_model\"][\"config\"][\"model_path\"] = \"lllyasviel/control_v11p_sd15_inpaint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlnet UNET conversion\n",
    "\n",
    "olive_config = None\n",
    "submodel_name = \"unet_controlnet\"\n",
    "olice_config_path = script_dir / f\"config_{submodel_name}.json\"\n",
    "olive_config_file = open(olice_config_path, \"r\")\n",
    "olive_config = json.load(olive_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-01 16:54:09,662] [INFO] [engine.py:181:setup_accelerators] Running workflow on accelerator specs: gpu-dml\n",
      "[2023-11-01 16:54:09,682] [INFO] [engine.py:926:_run_pass] Running pass convert:OnnxConversion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Axodox\\miniconda3\\envs\\olive-3x\\lib\\site-packages\\diffusers\\models\\resnet.py:139: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "c:\\Users\\Axodox\\miniconda3\\envs\\olive-3x\\lib\\site-packages\\diffusers\\models\\resnet.py:152: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if hidden_states.shape[0] >= 64:\n",
      "c:\\Users\\Axodox\\miniconda3\\envs\\olive-3x\\lib\\site-packages\\diffusers\\models\\autoencoder_kl.py:290: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not return_dict:\n",
      "c:\\Users\\Axodox\\miniconda3\\envs\\olive-3x\\lib\\site-packages\\torch\\onnx\\_internal\\jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\jit\\passes\\onnx\\shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "c:\\Users\\Axodox\\miniconda3\\envs\\olive-3x\\lib\\site-packages\\torch\\onnx\\utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\jit\\passes\\onnx\\shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "c:\\Users\\Axodox\\miniconda3\\envs\\olive-3x\\lib\\site-packages\\torch\\onnx\\utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\jit\\passes\\onnx\\shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-01 16:54:17,853] [INFO] [engine.py:926:_run_pass] Running pass optimize:OrtTransformersOptimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There is no gpu for onnxruntime to do optimization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-01 16:54:26,530] [INFO] [footprint.py:183:create_pareto_frontier] pareto frontier points: 1_OrtTransformersOptimization-0-d013a837061a70253453f970b4ea728d \n",
      "{\n",
      "  \"latency-avg\": 52.17608\n",
      "}\n",
      "[2023-11-01 16:54:26,531] [INFO] [engine.py:608:create_pareto_frontier_footprints] Output all 1 models\n",
      "[2023-11-01 16:54:26,532] [INFO] [engine.py:359:run] Run history for gpu-dml:\n",
      "[2023-11-01 16:54:26,533] [INFO] [engine.py:634:dump_run_history] Please install tabulate for better run history output\n",
      "[2023-11-01 16:54:26,535] [INFO] [engine.py:374:run] No packaging config provided, skip packaging artifacts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{AcceleratorSpec(accelerator_type=<Device.GPU: 'gpu'>, execution_provider='DmlExecutionProvider', vender=None, version=None, memory=None, num_cores=None): <olive.engine.footprint.Footprint at 0x1f0f97bf460>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Olive\n",
    "olive_run(olive_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
